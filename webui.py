import os
import gradio as gr
import whisper
import tempfile
import numpy as np
import soundfile as sf
import json
import shutil
from config.config import Config
from env import get_app_root
from qa.interaction import chat_with_gcode

__AVATAR = (
    os.path.join(get_app_root(), "resource/avatar/user.png"),
    os.path.join(get_app_root(), "resource/avatar/gcode_assistant.png")
)

# 1.ä¸å‡†ç¡® Pocketsphinx
# def audio_to_text(audio_path):
#     model_path = "D:/Anaconda/download/envs/gcode/Lib/site-packages/speech_recognition/pocketsphinx-data/zh-CN/zh_cn.cd_cont_5000"
#
#     ps = Pocketsphinx(
#         hmm=model_path,
#         lm="D:/Anaconda/download/envs/gcode/Lib/site-packages/speech_recognition/pocketsphinx-data/zh-CN/zh_cn.lm.bin",
#         dic="D:/Anaconda/download/envs/gcode/Lib/site-packages/speech_recognition/pocketsphinx-data/zh-CN/zh_cn.dic"
#     )
#
#     ps.decode(audio_file=audio_path)
#     return ps.hypothesis()
# 2.å¾ˆæ…¢
# def audio_to_text(audio_path):
#     model = whisper.load_model("large")  # å¯é€‰ï¼štiny, base, small, medium, largeï¼Œè¶Šæ¥è¶Šæ…¢
#     result = model.transcribe(audio_path)
#     return result["text"]
def audio_to_text(audio_path):
    # å¯é€‰ï¼štiny, base, small, medium, large
    # model = whisper.load_model("medium")
    # result = model.transcribe(audio_path)
    # return result["text"]
    
    # å§‹ç»ˆè¿”å›å›ºå®šæ–‡æœ¬
    # è¿™é‡Œæ¼”ç¤ºç”¨çš„ï¼Œåšç¡¬ç¼–ç çš„
    return "æˆ‘è¦ä½¿ç”¨å¤–åœ†å·¥è‰ºåŠ å·¥ä¸€ä¸ªå¤–åœ†ï¼ŒCnæ˜¯2ï¼ŒLæ˜¯100ï¼ŒTræ˜¯0.5ï¼ŒCræ˜¯1ï¼ŒFæ˜¯300"


# æ¸…ç©ºéŸ³é¢‘è¾“å…¥
def reset_audio_input():
    return None


def run_webui():
    with gr.Blocks() as demo:
        with gr.Row():  # æ¨ªå‘å¸ƒå±€
            audio_input = gr.Audio(source="microphone", type="filepath", label="è¯­éŸ³è¾“å…¥", scale=1)
            reset_button = gr.Button("é‡æ–°è¾“å…¥", scale=0)  # æ·»åŠ æŒ‰é’®

        chat_app = gr.ChatInterface(
            chat_with_gcode,
            title="Gä»£ç ç¼–ç¨‹åŠ©æ‰‹ğŸ“’",
            description="æ‚¨å¯ä»¥å’¨è¯¢å…³äºGJ306æ•°æ§ç³»ç»Ÿå’ŒGä»£ç ç¼–ç¨‹çš„é—®é¢˜",
            theme="default",
            examples=[
                "æ‚¨å¥½",
                "G00æŒ‡ä»¤çš„ä½œç”¨æ˜¯ä»€ä¹ˆï¼Ÿ",
                "å¦‚ä½•ä½¿ç”¨G76èºçº¹åˆ‡å‰Šå¾ªç¯ï¼Ÿ",
                "Gä»£ç ä¸­çš„G71å’ŒG72æœ‰ä»€ä¹ˆåŒºåˆ«ï¼Ÿ",
                "è¯·æä¾›GJ306ç³»ç»Ÿçš„å‚è€ƒæ‰‹å†Œ",
                "å¦‚ä½•è®¾ç½®åˆ€å…·è¡¥å¿ï¼Ÿ",
                "Mä»£ç å’ŒGä»£ç æœ‰ä»€ä¹ˆåŒºåˆ«ï¼Ÿ",
                "å¦‚ä½•ç¼–å†™å­ç¨‹åºï¼Ÿ",
                "è¯·ç”Ÿæˆä¸€ä¸ªç®€å•çš„è½¦å‰Šç¨‹åºç¤ºä¾‹",
                "å¦‚ä½•åœ¨GJ306ç³»ç»Ÿä¸­è¿›è¡Œåæ ‡ç³»è®¾å®šï¼Ÿ"
            ],
            cache_examples=False
        )

        # ç»‘å®šè¯­éŸ³è¾“å…¥åˆ° G ä»£ç åŠ©æ‰‹
        audio_input.change(
            fn=audio_to_text,
            inputs=audio_input,
            outputs=chat_app.textbox
        )

        # ç»‘å®š"é‡æ–°è¾“å…¥"æŒ‰é’®ï¼Œç‚¹å‡»åæ¸…ç©º audio_input
        reset_button.click(
            fn=reset_audio_input,
            inputs=[],
            outputs=audio_input
        )

    # æ­£ç¡®çš„ä½ç½®ï¼Œ.queue() åº”æ”¾åœ¨ demo ä¸Š
    demo.queue().launch(
        server_name="0.0.0.0",
        server_port=int(Config.get_instance().get_with_nested_params("server", "ui_port")),
        share=Config.get_instance().get_with_nested_params("server", "ui_share"),
        max_threads=10
    )


if __name__ == "__main__":
    run_webui()
